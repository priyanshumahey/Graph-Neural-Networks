{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning about Graph Neural Networks\n",
    "These lectures are made in conjuction with CS224W resources from Standford as well as the Graph Representation Learning book by William L. Hamilton.\n",
    "\n",
    "This module will go over and explain how graph neural networks work from the ground up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs are common data structures and work as a universal language for describing complex systems. Graphs are described as collections of objects that have interactions (or edges) between them. \n",
    "\n",
    "![Graph](./Images/graph.png)\n",
    "\n",
    "Graphs are able to establish relationships between points and are highly generizable. There are a lot different types of data that can be represented as a graph. Another huge benefit of graphs is they have a mathematical foundation which can be used to analyze and understand them. We can make use of them to make complex predictions. \n",
    "\n",
    "This is especially important for deep learning as modern deep learning is often specialized for simple, linear sequences and grids. \n",
    "\n",
    "Graphs and networks are much more complex to process. They possess arbitrary sizes and complex topological structure (i.e., no spatial locality like grids). They have no fixed node ordering and also lack reference points. Pair that with dynamic and multimodal features, they become really complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphs in Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A graph $G = (V, E)$ is described as having a set of nodes $V$ and a set of edges $E$ between the nodes. An edge going from node $u ∈ V$ to node $v ∈ V$ is denoted as $(u, v) ∈ E$. \n",
    "\n",
    "- **Simple Graphs**: These are graphs where there is at most one edge between each pair of nodes, no edges between a node and itself and all edges have no direction.\n",
    "\n",
    "One potential way to represent graphs is through adjacency matrixes: $A ∈ R^{|V|×|V|}$. Here, we would order the nodes in the graph such that every node indexes a particualr row and column in the adjacency matrix. Then, we represent the presence of edges as entries in the matrix: $\\textbf{A}[u,v] = 1$ if $(u,v) ∈ E$ and $\\textbf{A}[u,v] = 0$ otherwise. If a graph contains no directed edges, the graph will be symmetric but if it does have direction, then A may not be symmetric. There is also the chance that graphs have weighted edges where the entries in the adjacency matrix are arbitrary real-values rather than {0,1}.\n",
    "\n",
    "![Graph](./Images/admat.png)\n",
    "\n",
    "Since graphs may often be sparse, we can also represent graphs using an adjacency list. **Adjacency lists** are easier to work with if the network is large and spare and it allows us to quickly retrieve all neighbors of a given node. For example, for the directed graph above, we can create an adjacency list as such:\n",
    "\n",
    "1: 4\n",
    "\n",
    "2: 1\n",
    "\n",
    "3:\n",
    "\n",
    "4: 2, 3\n",
    "\n",
    "It is also possible for graphs to have different kinds of edges beyond undirected, weighted and directed edges. We can expand edge notation to include an edge or relation type τ, e.g., $(u, τ, v) ∈ E$ and we can define one adjacency matrix $\\textbf{A}_{τ}$ per edge type. We call these **mutli-relational** graphs and this entire graph can be summarized using the adjacency tensor $A ∈ R^{|V|×|R|×|V|}$ where $R$ is the set of relations. There are two important subsets of mutli-relationship graphs:\n",
    "\n",
    "1. **Heterogeneous Graphs**: Heterogenous graphs have nodes with imbued types. They contain either multiple types of objects or multiple types of links. For these sorts of graphs, edges typically have to follow some sort of constraint. The most common is what specific types of objects can attach to. \n",
    "2. **Mutliplex Graphs**: Multiplex graphs assume that graphs can be made into a set of $k$ layers. Nodes are replicated accross layers but each layer has differing connectivity. Inter-layer edge types can exist to connect same nodes across layers. \n",
    "\n",
    "We also have attributes or features associated with a graph. These can be represented with a real-valued matrix $X ∈ R^{|V |×m}$ where the ordering is assumed to be the same as the ordering in the adjacency matrix. \n",
    "\n",
    "Node degrees are also another important concept to understand for undirected graphs. A **node degree, $k_{i}$** is the number of edges adjacent to Node $i$. For example, \n",
    "\n",
    "![Graph](./Images/ND4.png)\n",
    "\n",
    "$k_{A}=4$\n",
    "\n",
    "**Avg. Degree:** = $\\bar{k}=\\langle k \\rangle = \\frac{1}{N}\\sum_{N}^{i=1}{k_{i}}=\\frac{2E}{N}$\n",
    "\n",
    "For directed networks, we define an **in-degree** and an **out-degree**. The (total) degree of a node is the sum of in- and out- degrees.\n",
    "\n",
    "![Graph](./Images/NDDirected.png)\n",
    "\n",
    "$k_{C}^{in} = 2$ and $k_{C}^{out}=1$ and thus $k_{C}=3$\n",
    "\n",
    "$\\bar{k} = \\frac{E}{N}$ and here $\\bar{k^{in}} = \\bar{k^{out}}$\n",
    "\n",
    "**Bipartite graphs** are graphs whose nodes can be divided into two disjoint sets $U$ and $V$ such that every link connects a node in $U$ to one in $V$; that is, $U$ and $V$ are **independent sets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning On Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For machine learning with graphs, we don't necesarily rely on the typical supervised and unsupervised systems to provide us information about the graphs. We'll start off by discussing what methods would be helpful for machine learning on graphs and discuss their implementation. With deep learning on graphs, our main goal is to input a network and then have an output of predictions which could be node labels, new links, generated graphs and subgraphs, etc, etc.\n",
    "\n",
    "![Graph](./Images/GNNDL.png)\n",
    "\n",
    "In traditional machine learning, a lot of feature engineering is required but with representation learning, the network is able to automatically learn the features. We can think of representation learning as a way to map nodes of a graph to d-dimensional embeddings such that similar nodes in the network are embedded close together.\n",
    "\n",
    "\n",
    "**Node Classification** is when the goal is to predict the label $y_{u}$ which could be a type, category, or attribute associated with all the notes $u ∈ V$ when we only given the true labels on a training set of nodes $V_{train}∈ V$. This is the most popular machine learning task done on graph data. Node classification may appear to be somewhat similar to standard supervised classification, but there are many important differences to consider. The most important thing to consider is that the nodes on a graph are not independent and identically distributed. With supervised learning, we assume the datapoints are statistically independent from all other datapoints and that they are identically distributed. For graphs, its a good idea to leverage their connectedness through ideas such as **homophily**, **structural equivalence** and **heterophily**.\n",
    "- Homophily: This is the tendency for nodes to share atteributes with their neighbors in the graph. \n",
    "- Structural equivalence: This is the idea that nodes with similar local neighborhood structures will have similar lables.\n",
    "- Heterophily: Presumes that nodes have preferentially connected to nodes with different labels. \n",
    "\n",
    "**Link Prediction** or **Relation Prediction** is a method to predict whether there are missing links between two nodes. The standard set up for this is that \n",
    "\n",
    "**Graph Classification**: Categorize different graphs\n",
    "\n",
    "**Clustering:** Detecting if nodes are forming an interconnected community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you should pause and take a look at `Notebook 1.ipynb` in the Learning folder to get a better sense of how to program graphs using NetworkX. For more information, take a look at the [documentation](https://networkx.org/documentation/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Methods for Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Networks 1: GNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Networks 2: Design Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory of Graph Neural Networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
