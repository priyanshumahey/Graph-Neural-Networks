{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Networks 1: GNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Graph Neural Networks\n",
    "Graph neural networks are examples of deep graph encoders. Graph neural networks are general frameworks to define deep neural networks on graph data. To define a deep neural network over general graphs, we need to define a new kind of deep learning architecture. \n",
    "\n",
    "Why do we not simply use mutlilayer preceptrons on a flattened adjacency matrix? That's because it would depend on the arbitrary order of nodes that we used in the adjacency matrix. This type of model would not be permutation invariant. \n",
    "\n",
    "Deep neural networks will take the entire graph as a structure and then take information such as edges, nodes, layers, etc. Then we can apply a deep learning network to study it and create outputs.\n",
    "\n",
    "With deep learning algorithms, we'll be able to solve node classification, link prediction, community detection and network similarity.\n",
    "\n",
    "\n",
    "### Basics of Deep Learning\n",
    "Supervised learning is when we are given input x, and the goal is to predict lable y. Input x can be a vector of numbers, sequences, matrices, graphs, etc. We then formulate the task  as an optimization problem. We want to optimize the parameters for the deep learning network such that the loss function results in as little loss as possible. \n",
    "\n",
    "With gradient descent, we can iteratively apply it and update weights in the opposite direction of the gradient until the gradient converges. An example of a gradient descent algorithm is the stochastic gradient descent algorithm. This picks a different minibatch containing a subset of the data and uses that as the input to prevent the gradient from requiring computing the entire dataset everytime gradient descent occurs. \n",
    "\n",
    "None-linearity is another important feature of deep learning algorithms to understand. We need to introduce non-linear functions that create relationships that are non-linear. For example, we could use ReLU and Sigmoid functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning for Graphs\n",
    "One of the most important things we need to discuss first is how the graph is actually passed into the deep neural network. First, let's assume that we have an input graph $G=(V,E)$ with A as the adjacency matrix (assume binary). The matrix of it's node features are described by $X \\in \\mathbb{R}^{m \\times |V|}$.\n",
    "\n",
    "A really naive approach is to join adjacency matrix and features. Then, we would feed them into a deep neural network. There is no fixed notion of locality or sliding we can apply on a graph and graphs are permutation invariant (graph doesn't have a canonical order of the nodes).\n",
    "\n",
    "#### Permutation equivariance\n",
    "For a given node representation, consider we learn a function f that maps a graph G = (A, X) to a matrix $\\mathbb{R}^{m \\times |V|}$.. Graph has m nodes and each row is the embedding of a node. Similarly, if this property hold for any pair of otrder plan i and j, we say f is a permutation equivariant function. \n",
    "\n",
    "\n",
    "### Graph Convolutional Networks\n",
    "Read a bit more into this separately in depth as this is highly important.\n",
    "https://www.cs.mcgill.ca/~wlh/grl_book/files/GRL_Book.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Neural Networks 2: Design Space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
